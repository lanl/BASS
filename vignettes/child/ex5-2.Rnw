
In this example, we consider a NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections conducted in an anechoic wind tunnel \citep{Lichman2013}.  The response is scaled sound pressure level, in decibels.  There are five inputs: (1) Frequency, in hertz; (2) angle of attack, in degrees; (3) chord length, in meters; (4) free-stream velocity, in meters per second; and (5) suction side displacement thickness, in meters.  The data have 1503 combinations of these inputs, some of which are collinear (variables 2 and 5 have correlation of 0.75).
<<eval=F>>=
dd <- read.table('https://archive.ics.uci.edu/ml/
  machine-learning-databases/00291/airfoil_self_noise.dat')
@
<<include=F>>=
dd <- read.table('https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat')
@

We set aside 200 input combinations to use for testing.
<<c5-1, cache=T>>=
set.seed(0)
test <- sample(nrow(dd), size=150)
x <- dd[-test, 1:5]
y <- dd[-test, 6]
@
We fit a BASS model using tempering.
<<c5-2, cache=T, dependson='c5-1'>>=
mod <- bass(x, y, nmcmc = 20000, nburn = 10000, thin = 10,
            temp.ladder = 1.1^(0:5), verbose = FALSE)
@
We can predict as we have before.  However, this prediction is for the mean function.
<<c5-3, cache=T, dependson='c5-2'>>=
x.test <- dd[test, 1:5]
y.test <- dd[test, 6]
pred <- predict(mod, x.test)
@
Now, if we are interested in predicting actual data rather than the mean function, we can incorporate uncertainty from our estimate of $\sigma^2$.
<<>>=
pred.error <- pred + matrix(
  rnorm(nrow(pred) * ncol(pred), 0, sqrt(mod$s2)), nrow = nrow(pred))
q1 <- apply(pred.error, 2, quantile, probs = 0.05)
q2 <- apply(pred.error, 2, quantile, probs = 0.95)
mean((q1 < y.test) & (q2 > y.test))
@
This puts our empirical coverage near where we would expect it to be.
We can plot our 90\% prediction intervals as follows, shown in Figure~\ref{fig:ex5plot1}.
<<ex5plot1, fig.cap='Prediction performance -- air foil data.',fig.height=6*.7, fig.width=6*.7>>=
plot(y.test, colMeans(pred))
abline(a = 0, b = 1, col = 2)
segments(y.test, q1, y.test, q2, col = "lightgray")
@

Next, we can obtain and plot the Sobol' decomposition, shown in Figure~\ref{fig:ex5plot2}.  We disregard the dependence among the input variables.
<<ex5plot2, cache=T, fig.height=6*.7, fig.width=12*.7, out.width='.8\\linewidth', fig.cap='Sobol decomposition -- air foil data.'>>=
sens <- sobol(mod, verbose = FALSE)
plot(sens)
@

The uncertainty in the sensitivity indices in Figure~\ref{fig:ex5plot2} is significant and helps us to understand that there are many possible models for these data that use different variables and interactions.  The proper characterization of this uncertainty would be impossible if our RJMCMC chain was stuck in a mode.  Hence, tempering is important in this problem.  By exploring the posterior modes, tempering allows us to find not just a model that predicts well, but all the models that predict well.
