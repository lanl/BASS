% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bass.R
\name{bass}
\alias{bass}
\title{Bayesian Adaptive Spline Surfaces (BASS)}
\usage{
bass(
  xx,
  y,
  maxInt = 3,
  maxInt.func = 3,
  maxInt.cat = 3,
  xx.func = NULL,
  degree = 1,
  maxBasis = 1000,
  npart = NULL,
  npart.func = NULL,
  nmcmc = 10000,
  nburn = 9000,
  thin = 1,
  g1 = 0,
  g2 = 0,
  s2.lower = 0,
  h1 = 10,
  h2 = 10,
  a.tau = 0.5,
  b.tau = NULL,
  birth.type = "NKD",
  w1 = 5,
  w2 = 5,
  w3 = c(1, 2, 3),
  nint.prior = 1/(1:ncol(xx)),
  nint.proposal = 1/(1:maxInt),
  beta.prior = "g",
  temp.ladder = NULL,
  start.temper = NULL,
  curr.list = NULL,
  save.yhat = TRUE,
  small = FALSE,
  verbose = TRUE,
  ret.str = F
)
}
\arguments{
\item{xx}{a data frame or matrix of predictors.  Categorical predictors should be included as factors.}

\item{y}{a response vector (scalar response) or matrix (functional response).  Note: If \code{sum(y^2)} is large (i.e. \code{1e10}), please center/rescale (and rescale \code{g1} and \code{g2} if necessary).}

\item{maxInt}{integer for maximum degree of interaction in spline basis functions.  Defaults to the number of predictors, which could result in overfitting.}

\item{maxInt.func}{(functional response only) integer for maximum degree of interaction in spline basis functions describing the functional response.}

\item{maxInt.cat}{(categorical input only) integer for maximum degree of interaction of categorical inputs.}

\item{xx.func}{a vector, matrix or data frame of functional variables.}

\item{degree}{degree of splines.  Stability should be examined for anything other than 1.}

\item{maxBasis}{maximum number of basis functions.  This should probably only be altered if you run out of memory.}

\item{npart}{minimum number of non-zero points in a basis function.  If the response is functional, this refers only to the portion of the basis function coming from the non-functional predictors. Defaults to 20 or 0.1 times the number of observations, whichever is smaller.}

\item{npart.func}{same as npart, but for functional portion of basis function.}

\item{nmcmc}{number of RJMCMC iterations.}

\item{nburn}{number of the \code{nmcmc} iterations to disregard.}

\item{thin}{keep every \code{thin} samples}

\item{g1}{shape for IG prior on \eqn{\sigma^2}.}

\item{g2}{scale for IG prior on \eqn{\sigma^2}.}

\item{s2.lower}{lower bound for s2. Turns IG prior for s2 into a truncated IG.}

\item{h1}{shape for gamma prior on \eqn{\lambda}.}

\item{h2}{rate for gamma prior on \eqn{\lambda}.  This is the primary way to control overfitting.  A large value of \code{h2} favors fewer basis functions.}

\item{a.tau}{shape for gamma prior on \eqn{\tau}.}

\item{b.tau}{rate for gamma prior on \eqn{\tau}. Defaults to one over the number of observations, which centers the prior for the basis function weights on the unit information prior.}

\item{birth.type}{default is \code{"NKD"}. Alternative option \code{"coinflip"} allows for exploration of higher-order interaction terms.}

\item{w1}{nominal weight for degree of interaction, used in generating candidate basis functions.  Should be greater than 0.}

\item{w2}{nominal weight for variables, used in generating candidate basis functions.  Should be greater than 0.}

\item{w3}{tuning parameters for generating candidate basis functions when \code{birth.type = "coinflip"}. See \code{makeCoinWeights()} for details.}

\item{nint.prior}{vector of prior probabilities for interaction orders. Ignored unless \code{birth.type = "coinflip"}.}

\item{nint.proposal}{vector of sampling weights for the expected interaction order. Ignored unless \code{birth.type = "coinflip"}.}

\item{beta.prior}{what type of prior to use for basis coefficients, "g" or "jeffreys"}

\item{temp.ladder}{temperature ladder used for parallel tempering.  The first value should be 1 and the values should increase.}

\item{start.temper}{when to start tempering (after how many MCMC iterations). Defaults to 1000 or half of burn-in, whichever is smaller.}

\item{curr.list}{list of starting models (one element for each temperature), could be output from a previous run under the same model setup.}

\item{save.yhat}{logical; should predictions of training data be saved?}

\item{small}{logical; if true, returns a smaller object by leaving out \code{curr.list} and other unnecessary objects.  Use in combination with \code{save.yhat} to get smaller memory footprint for very large models.}

\item{verbose}{logical; should progress be displayed?}

\item{ret.str}{logical; return data and prior structures}
}
\value{
An object of class 'bass'.  The other output will only be useful to the advanced user.  Rather, users may be interested in prediction and sensitivity analysis, which are obtained by passing the entire object to the predict.bass or sobol functions.
}
\description{
Fits a BASS model using RJMCMC.  Optionally uses parallel tempering to improve mixing.  Can be used with scalar or functional response.  Also can use categorical inputs.
}
\details{
Explores BASS model space by RJMCMC.  The BASS model has \deqn{y = f(x) + \epsilon,  ~~\epsilon \sim N(0,\sigma^2)} \deqn{f(x) = a_0 + \sum_{m=1}^M a_m B_m(x)} and \eqn{B_m(x)} is a BASS basis function (tensor product of spline basis functions). We use priors \deqn{a \sim N(0,\sigma^2/\tau (B'B)^{-1})} \deqn{M \sim Poisson(\lambda)} as well as the priors mentioned in the arguments above.
}
\examples{
inst/examples.R

}
\seealso{
\link{predict.bass} for prediction and \link{sobol} for sensitivity analysis.
}
\keyword{analysis}
\keyword{data}
\keyword{functional}
\keyword{nonparametric}
\keyword{regression}
\keyword{splines}
